name: "Numbast Docs Build/Upload"
description: "Builds the Numbast docs and uploads them as workflow artifacts."
inputs:
  upload_workflow_artifact:
    description: "Uploads the built docs as a workflow artifact (actions/upload-artifact)."
    required: false
    default: "true"
  build_tagged_versions:
    description: "If true, build versioned docs listed in docs/nv-versions.json."
    required: false
    default: "false"
runs:
  using: "composite"
  steps:
    - name: Create conda environment
      shell: bash --noprofile --norc -euo pipefail {0}
      run: |
        conda create -n docs-build python=3.12 -y
    # Install required dependencies
    - name: Install build dependencies
      shell: bash --noprofile --norc -euo pipefail {0}
      run: |
        conda install -n docs-build -c conda-forge clangdev=20 cmake>=3.29 ninja flex bison git c-compiler cxx-compiler make cuda-cudart -y
    - name: Install Python dependencies for docs
      shell: bash --noprofile --norc -euo pipefail {0}
      run: |
        conda run -n docs-build python -m pip install --upgrade pip
        # Build and install Numbast from Source
        conda run -n docs-build ast_canopy/build.sh
        conda run -n docs-build python -m pip install --pre numbast/
        # Minimum dependencies for Numba-CUDA to run
        conda run -n docs-build python -m pip install cuda-python cuda-core
        # Install Sphinx dependencies
        conda run -n docs-build python -m pip install sphinx nvidia-sphinx-theme sphinx-copybutton
    - name: Print Installed Packages
      shell: bash --noprofile --norc -euo pipefail {0}
      run: |
        conda list -n docs-build
    - name: Resolve tagged docs matrix
      if: ${{ inputs.build_tagged_versions == 'true' }}
      id: tagged-versions
      shell: bash --noprofile --norc -euo pipefail {0}
      run: |
        matrix=$(python - <<'PY'
        import json
        from pathlib import Path

        entries = json.loads(Path("docs/nv-versions.json").read_text())
        versions = []
        for entry in entries:
            version = str(entry.get("version", "")).strip()
            if version and version != "latest":
                versions.append(version)

        print(json.dumps(versions))
        PY
        )
        echo "matrix=${matrix}" >> "$GITHUB_OUTPUT"
    - name: Build tagged docs from matrix
      if: ${{ inputs.build_tagged_versions == 'true' && steps.tagged-versions.outputs.matrix != '[]' }}
      shell: bash --noprofile --norc -euo pipefail {0}
      env:
        TAGGED_DOCS_MATRIX: ${{ steps.tagged-versions.outputs.matrix }}
      run: |
        tagged_docs_root="${RUNNER_TEMP}/numbast-tagged-docs"
        rm -rf "${tagged_docs_root}"
        mkdir -p "${tagged_docs_root}"

        mapfile -t tagged_versions < <(python - <<'PY'
        import json
        import os

        for version in json.loads(os.environ["TAGGED_DOCS_MATRIX"]):
            print(version)
        PY
        )

        original_ref=$(git rev-parse --verify HEAD)
        restore_checkout() {
          git checkout --force "${original_ref}" >/dev/null 2>&1 || true
        }
        trap restore_checkout EXIT

        for version in "${tagged_versions[@]}"; do
          tag="v${version}"

          if ! git rev-parse --quiet --verify "${tag}^{commit}" >/dev/null; then
            echo "error: tag '${tag}' does not exist"
            exit 1
          fi

          echo "Building docs for ${tag}"
          git checkout --detach "${tag}"
          conda run -n docs-build bash ast_canopy/build.sh
          conda run -n docs-build python -m pip install --pre --no-deps --force-reinstall ./numbast/
          conda run -n docs-build env SPHINX_NUMBAST_VER="${version}" bash ci/build_docs.sh latest-only

          version_output_dir="${tagged_docs_root}/${version}"
          rm -rf "${version_output_dir}"
          mkdir -p "${version_output_dir}"
          cp -a "docs/build/html/latest/." "${version_output_dir}/"
        done

        trap - EXIT
        restore_checkout
    # Build docs for the current checkout (latest)
    - name: Build all docs
      shell: bash --noprofile --norc -euo pipefail {0}
      run: |
        if [[ "${{ inputs.build_tagged_versions }}" == "true" ]]; then
          conda run -n docs-build bash ast_canopy/build.sh
          conda run -n docs-build python -m pip install --pre --no-deps --force-reinstall ./numbast/
        fi
        conda run -n docs-build ci/build_docs.sh
    - name: Copy tagged docs into final output
      if: ${{ inputs.build_tagged_versions == 'true' && steps.tagged-versions.outputs.matrix != '[]' }}
      shell: bash --noprofile --norc -euo pipefail {0}
      env:
        TAGGED_DOCS_MATRIX: ${{ steps.tagged-versions.outputs.matrix }}
      run: |
        tagged_docs_root="${RUNNER_TEMP}/numbast-tagged-docs"
        mapfile -t tagged_versions < <(python - <<'PY'
        import json
        import os

        for version in json.loads(os.environ["TAGGED_DOCS_MATRIX"]):
            print(version)
        PY
        )

        for version in "${tagged_versions[@]}"; do
          version_output_dir="docs/build/html/${version}"
          rm -rf "${version_output_dir}"
          mkdir -p "${version_output_dir}"
          cp -a "${tagged_docs_root}/${version}/." "${version_output_dir}/"
        done
    # Copy all docs to the right folder
    - name: Move docs to right folder
      shell: bash --noprofile --norc -euo pipefail {0}
      run: |
        mkdir -p _site
        cp -rf ./docs/build/html/* _site/
        touch _site/.nojekyll
    # Update docs as workflow artifact:
    - name: Upload artifact
      if: ${{ inputs.upload_workflow_artifact == 'true' }}
      uses: actions/upload-artifact@v4
      with:
        name: docs
        path: _site/
        compression-level: 0
